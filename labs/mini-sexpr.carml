#@(#) A Miniture SExpression library for carML
#@(#) mainly aimed at getting the carML compiler out of the C system
#@(#) should be mainly compatible with the SExpression-based IR that
#@(#) carML/C generates.
#@(#) Meant to help even FURTHER accelerate the bootstrap process,
#@(#) since it's smaller than a full SExpression library, and works
#@(#) with the Golang output
#
# the shame is, given carML's current
# type system, there are many work-arounds
# required to make the below work:
# - the type system can't tell ref[SExpression] can be flattened to SExpression
# - some things should be automatically passed around as ref[Type] but you have to manually do that
# - lots of ref[Any] could be turned into a `const`...
#
# probably lots of other hacks as I
# go through it. Luckily, once I move
# past where the C compiler is, I can
# start to handle some of the debt I've
# accrued.

type SExpression {
    Nil
    Atom string int
    String string int
    # making these strings for now to make it easier to
    # create, since I haven't written standard functions
    # to convert string=>int/float yet.
    # eventually, those should be gadgets...
    #
    # additionally, including an `int` here for the 
    # offset, since I haven't dont destructuring binds
    # yet...
    Int string int
    Float string int
    Char string int
    Bool bool int
    List array[SExpression] int
    Error string int
    # Maybe should have an internal type that
    # isn't exported, and an external type that
    # is, so as to remove the two constructors
    # below...
    Null
    EndList int
    EndArray int
    EndFile
}

record Token {
    lexeme:string
    lexeme_offset:int
    lexeme_type:int
}

# add a simple reader system below
# should be able to construct & read
# SExpression-based syntax
#
# What will this be used for? Why,
# for bootstrapping a compiler in carML
# itself really.

def is_whitespace ch:char => bool = {
    match ch with
        ' ' => true
        '\t' => true
        '\n' => true
        '\v' => true
        '\r' => true
        '\b' => true
        else => false
    end
}

def take_while_white src:string start:int => int = {
    # take... on... me...
    # _softly_ take on me
    # take... me... on...
    # _softly_ take on me
    # I'll be... gone...
    # In a day or twoooooooo
    # _synths_
    var idx:int = start
    var ch:char = (get src start)
    # I *hate* how low level this is...
    when (is_whitespace ch) do {
        while (is_whitespace ch) do {
            set! ch $ get src idx
            set! idx $ + idx 1
        }
        return $ - idx 1
    }
    idx
}

def take_until_break src:string start:int => int = {
    var idx:int = start
    var ch:char = ' '
    if (> idx $ len src) then idx
    else {
        set! ch $ get src idx
        while (every (< idx $ len src) (is_symbolic ch)) do {
            set! idx $ + idx 1
            set! ch $ get src idx
        }
        idx
    }
}

def next src:string start_offset:int => Token = {
    # NOTE I had an idea about how to fix the offset
    # issue: instead of trying to read the string AND
    # process lexemes, what we need is to go old-School
    # Wirth style with our RDP: have a function, next,
    # which returns a Token struct with the next lexeme,
    # it's length, and type

    when (>= start_offset $ len src) do (return $ make-struct Token "" start_offset 98)

    val offset:int = (take_while_white src start_offset)
    val ch:char = (get src offset)
    var idx:int = offset
    var state:int = 0
    # yet again, I really need to make TCO a thing, since
    # this function would be so much more nicely expressed
    # as a simple tail recursive function...
    match ch with
        '(' => (return $ make-struct Token "(" offset 1)
        ')' => (return $ make-struct Token ")" offset 2)
        '[' => (return $ make-struct Token "[" offset 3)
        ']' => (return $ make-struct Token "]" offset 4)
        z given (is_numeric ch) => {
            while (< idx $ len src) do {
                match state with
                    # integer
                    0 => match ch with
                        '.' => (set! state 1)
                        _ given (is_numeric ch) => (set! state 0)
                        _ given (is_symbolic ch) => (set! state 2)
                        _ given (not $ is_symbolic ch) => (return $ make-struct Token (string_slice src offset idx) offset 5)
                        else => (set! state 0)
                    end
                    # float
                    1 => match ch with
                        '.' => (set! state 2)
                        _ given (is_numeric ch) => (set! state 1)
                        _ given (is_symbolic ch) => (set! state 2)
                        _ given (not $ is_symbolic ch) => (return $ make-struct Token (string_slice src offset idx) offset 6)
                        else => (set! state 1)
                    end
                    # atom
                    2 => when (not $ is_symbolic ch) do (return $ make-struct Token (string_slice src offset idx) offset 7)
               end
               set! idx $ + idx 1
               when (< idx $ len src) do (set! ch $ get src idx)
            }
        }
        # atoms
        _ given (is_symbolic ch) => {
            while (every (< idx $ len src) (is_symbolic ch)) do {
                set! ch $ get src idx
                set! idx $ + idx 1
            }
            return $ make-struct Token (string_slice src offset $ - idx 1) offset 7
        }
        # strings
        '"' => {
            set! idx $ + idx 1
            if (>= idx $ len src) then
                (return $ make-struct Token "malformed string" offset 99)
            else
                (set! ch $ get src idx)
            while (every (!= ch '"') (< idx $ len src)) do {
                match ch with
                    '\\' => (set! idx $ + idx 2)
                    else => (set! idx $ + idx 1)
                end
                when (< idx $ len src) do (set! ch $ get src idx)
            }
            return $ make-struct Token (string_slice src offset $ + idx 1) offset 8
        }
        # characters
        '#' => {
            var tmp:string = ""
            var tidx:int = 0
            set! idx $ + idx 1
            when (>= (+ idx 1) $ len src) do (return $ make-struct Token "malformed character" offset 99)
            when (!= (get src idx) '\\') do (return $ make-struct Token "character must be followed by \\" offset 99)
            # NOTE what we need to do is read until we hit some non-symbolic, and then attempt to tell
            # if we have a named character or a single one...
            # for example, we might have:
            #
            # - #\n (the letter n)
            # - #\newline (the literal ASCII newline)
            # we want to support both, but also need to make sure that named characters are actual names we can
            # parse...
            #
            # XXX GAH I just realized tho that this means we *cannot* rely on the simple offset
            # and instead need to do some helper calculations here in the sizing... this could
            # get hairy...
            #
            # You'll notice below that the calculations for offset are odd. This is because
            # I'm actually calculating; length of character prefix (2) + length of named character,
            # but we subtract one so that the normal offset + len works. so, some examples:
            # - `#\n` the letter 'n', should be three, actually two
            # - `#\newline` the ASCII newline, '\n', should be nine, actually 8
            set! tidx $ take_until_break src $ + idx 1
            set! tmp $ string_slice src (+ idx 1) tidx
            match tmp with
                # if we only have *one* character, don't bother checking...
                _ given (eq? 1 $ len tmp) => (return $ make-struct Token tmp (+ offset 2) 9)
                # it would be *so* much more reasonable here to return a value into
                # a val and then use that to call `return` once...
                #
                # once the new compiler is working, I need to move to a correct
                # "everything is a value" system...
                "newline" => (return $ make-struct Token "\n" (+ offset 8) 9)
                "tab" => (return $ make-struct Token "\t" (+ offset 4) 9)
                "carriage" => (return $ make-struct Token "\r" (+ offset 9) 9)
                "bell" => (return $ make-struct Token "\a" (+ offset 5) 9)
                "vtab" => (return $ make-struct Token "\v" (+ offset 5) 9)
                "backspace" => (return $ make-struct Token "\b" (+ offset 10) 9)
                "backslash" => (return $ make-struct Token "\\" (+ offset 10) 9)
                else => (return $ make-struct Token "incorrect named character" offset 99)
            end
        }
        else => (return $ make-struct Token " " 1 99)
    end
    # XXX: AAAAAAAAAAH... so imperative
    match state with
        0 => (return $ make-struct Token (string_slice src offset idx) offset 5)
        1 => (return $ make-struct Token (string_slice src offset idx) offset 6)
        2 => (return $ make-struct Token (string_slice src offset idx) offset 7)
    end
    return $ make-struct Token " " 1 99
}

def is_numeric ch:char => bool = {
    match ch with
        _ given (&& (>= ch '0') (<= ch '9')) => true
        '.' => true
        else => false
    end
}

def is_symbolic ch:char => bool = {
    match ch with
        '(' => false
        ')' => false
        '[' => false
        ']' => false
        '"' => false
        '\'' => false
        '#' => false
        _ given (is_whitespace ch) => false
        else => true
    end
}

def is_null_or_endp obj:SExpression => bool = {
    match obj with
        (SExpression.Null) => true
        (SExpression.EndList) => true
        (SExpression.EndArray) => true
        (SExpression.EndFile) => true
        else => false
    end
}

# this should ideally be replaced by a zero-cost abstraction
# gadget that writes things like List.map! or the like to
# simple Go/C functions, but for now, just like string-slice
# above, write this in carML itself
def shrink_array src:array[SExpression] cap:int length:int => array[SExpression] = {
    var ret : array[SExpression] = (make-array SExpression.Nil length $ SExpression.Nil)
    var idx : int = 0
    while (< idx length) do {
        set! (get ret idx) (get src idx)
        set! idx $ + idx 1
    }
    ret
}

# we really don't need much else beyond this part here
# we could honestly do this with append=>array as well,
# which would basically treat this as a stack, maybe by
# backing with a dequeue?
def read_list src:string start:int => SExpression = {
    # XXX for now, going to use an array, but I really thinkg
    # this would be an *ideal* location for deques...
    var ret:array[SExpression] = (make-array SExpression 128 $ SExpression.Nil)
    var ret_length:int = 128
    var tmp:SExpression = (sexpression_read src start)
    var idx:int = 0
    var offset:int = start
    while (not $ is_null_or_endp tmp) do {

        when (>= idx ret_length) do {
            return $ make-struct SExpression.Error "read_list array length overrun" start
        }

        set! (get ret idx) tmp
        set! idx $ + idx 1
        # actually, this is still wrong...
        # because we're just returning the *offset* in most
        # of our setups, but in lists we cannot just run a
        # string length check. I think here we can probably
        # do a check for most items, but of lists we have to
        # set the offset to be the offset of the final
        # #\)
        match tmp with
            (SExpression.List _ _) => (set! offset $ . tmp m_2)
            # a limit to what we can do here; because we write
            # these as an interface{} and what not in Golang, we
            # actually need to check each of the types here. Luckily,
            # it's probably better because I actually wasn't checking
            # an error was returned!
            (SExpression.Atom _ _) => (set! offset $ + (. tmp m_2) $ len $ . tmp m_1)
            (SExpression.String _ _) => (set! offset $ + (. tmp m_2) $ len $ . tmp m_1)
            (SExpression.Int _ _) => (set! offset $ + (. tmp m_2) $ len $ . tmp m_1)
            (SExpression.Float _ _) => (set! offset $ + (. tmp m_2) $ len $ . tmp m_1)
            # I don't think I can read bools based on this...
            (SExpression.Bool _ _) => (set! offset $ + (. tmp m_2) $ len $ . tmp m_1)
            (SExpression.Char _ _) => (set! offset $ + (. tmp m_2) $ len $ . tmp m_1)
            (SExpression.EndList _) => (set! offset $ + (. tmp m_1) 1)
            else => (return tmp)
        end
        set! tmp $ sexpression_read src offset
    }
    make-struct SExpression.List (shrink_array ret 128 idx) $ + offset 1
}

def read_char src:string offset:int => SExpression = {
    val tok : Token = (next src offset)
    if (eq? (. tok lexeme_type) 9) then
        (make-struct SExpression.Char (. tok lexeme) (. tok lexeme_offset))
    else
        (make-struct SExpression.Error "expected character" offset)
}

def read_atom src:string offset:int => SExpression = {
    val tok : Token = (next src offset)
    if (eq? (. tok lexeme_type) 7) then
        (make-struct SExpression.Atom (. tok lexeme) (. tok lexeme_offset))
    else
        (make-struct SExpression.Error "expected atom" offset)
}

def read_string src:string offset:int => SExpression = {
    val tok : Token = (next src offset)
    if (eq? (. tok lexeme_type) 8) then
        (make-struct SExpression.String (. tok lexeme) (. tok lexeme_offset))
    else
        (make-struct SExpression.Error "expected character" offset)
}

# NOTE (lojikil):
# I was originally going to implement a bunch of things in the
# core library, but then I realized I probably should actually
# make a module and have things work there. So, for now, I'm
# adding this helper here, and will work on making the rest
# of the module system workable...
def string_slice src:string start:int endpoint:int => string = {
    val len:int = (- endpoint start)
    var res:array[char] = (make-array char len)
    var idx:int = 0
    while (< idx len) do {
        set! (get res idx) $ get src $ + idx start
        set! idx $ + idx 1
    }
    make-string res
}

# it would be nice to enrich types here
# say that this is an SExpression, but also
# that the only types it will return are
# from Int, Float, Rational, Complex
# NOTE (lojikil) also, this would be a great place
# for default values: offset & start could be set
# freely...
def read_number src:string offset:int => SExpression = {
    val tok:Token = (next src offset)
    match (. tok lexeme_type) with
        5 => (make-struct SExpression.Int (. tok lexeme) (. tok lexeme_offset))
        6 => (make-struct SExpression.Float (. tok lexeme) (. tok lexeme_offset))
        else => (make-struct SExpression.Error "wanted to read a number, but other type returned" offset)
    end
}

def sexpression_read src:string start:int => SExpression = {
    # this would be so much nicer as a tuple here
    # we need a few things tho:
    # 1. unboxing tuple[char int] (for example) in Golang returns
    # 1. destructuring bind (`var ch, idx : tuple[char int] = ...`)
    # 1. making a `make-tuple` and allowing `,` in CALL
    val tok:Token = (next src start)
    match (. tok lexeme_type) with
        1 => (read_list src $ + start 1)
        2 => (make-struct SExpression.EndList $ + (. tok lexeme_offset) 1)
        #'[' => (read_array fh)
        #']' => (make-struct SExpression.EndArray)
        5 => (make-struct SExpression.Int (. tok lexeme) (. tok lexeme_offset))
        6 => (make-struct SExpression.Float (. tok lexeme) (. tok lexeme_offset))
        7 => (make-struct SExpression.Atom (. tok lexeme) (. tok lexeme_offset))
        8 => (make-struct SExpression.String (. tok lexeme) (. tok lexeme_offset))
        9 => (make-struct SExpression.Char (. tok lexeme) (. tok lexeme_offset))
        98 => (make-struct SExpression.EndFile)
        else => (make-struct SExpression.Error (. tok lexeme) (. tok lexeme_offset))
    end
}
